~/src/mddg ~/src/mddg
Processing dataset...

Processing Dataset:   0%|          | 0/2 [00:00<?, ?item/s]
Processing Dataset: 100%|██████████| 2/2 [00:00<00:00, 18196.55item/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Initializing pipeline...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:42<02:06, 42.17s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [01:18<01:17, 39.00s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [01:56<00:38, 38.11s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 26.34s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [02:04<00:00, 31.08s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Running pipeline...
Total output tokens: 123
Avg out tokens per prompt: 61.5
model_output/meta-llama/Meta-LLaMA-3-8B/toy/zero-shot_output.pkl
model_output/meta-llama/Meta-LLaMA-3-8B/toy/zero-shot_output_METADATA.json
Processing dataset...

Processing Dataset:   0%|          | 0/2 [00:00<?, ?item/s]
Processing Dataset: 100%|██████████| 2/2 [00:00<00:00, 16743.73item/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Initializing pipeline...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:35<01:45, 35.13s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [01:11<01:12, 36.09s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [01:45<00:35, 35.08s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:54<00:00, 24.59s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:54<00:00, 28.57s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Running pipeline...
Total output tokens: 1028
Avg out tokens per prompt: 514.0
model_output/meta-llama/Meta-LLaMA-3-8B-Instruct/toy/zero-shot_output.pkl
model_output/meta-llama/Meta-LLaMA-3-8B-Instruct/toy/zero-shot_output_METADATA.json
Processing dataset...

Processing Dataset:   0%|          | 0/2 [00:00<?, ?item/s]
Processing Dataset: 100%|██████████| 2/2 [00:00<00:00, 20213.51item/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Initializing pipeline...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:52<02:37, 52.37s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [01:49<01:49, 54.99s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [02:52<00:58, 58.61s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:03<00:00, 39.79s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:03<00:00, 45.76s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Running pipeline...
Total output tokens: 1141
Avg out tokens per prompt: 570.5
model_output/meta-llama/Meta-LLaMA-3-8B/toy/zero-shot-CoT_output.pkl
model_output/meta-llama/Meta-LLaMA-3-8B/toy/zero-shot-CoT_output_METADATA.json
Processing dataset...

Processing Dataset:   0%|          | 0/2 [00:00<?, ?item/s]
Processing Dataset: 100%|██████████| 2/2 [00:00<00:00, 15592.21item/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Initializing pipeline...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:56<02:49, 56.62s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [02:01<02:02, 61.26s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [03:28<01:13, 73.03s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:48<00:00, 52.33s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [03:48<00:00, 57.19s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Running pipeline...
Total output tokens: 852
Avg out tokens per prompt: 426.0
model_output/meta-llama/Meta-LLaMA-3-8B-Instruct/toy/zero-shot-CoT_output.pkl
model_output/meta-llama/Meta-LLaMA-3-8B-Instruct/toy/zero-shot-CoT_output_METADATA.json
Processing dataset...

Processing Dataset:   0%|          | 0/2 [00:00<?, ?item/s]
Processing Dataset: 100%|██████████| 2/2 [00:00<00:00, 14413.42item/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Initializing pipeline...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:33<01:39, 33.15s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [01:03<01:02, 31.25s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [01:35<00:31, 31.75s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:44<00:00, 22.62s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [01:44<00:00, 26.01s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Running pipeline...
Total output tokens: 146
Avg out tokens per prompt: 73.0
model_output/meta-llama/Meta-LLaMA-3-8B/toy/few-shot_output.pkl
model_output/meta-llama/Meta-LLaMA-3-8B/toy/few-shot_output_METADATA.json
Processing dataset...

Processing Dataset:   0%|          | 0/2 [00:00<?, ?item/s]
Processing Dataset: 100%|██████████| 2/2 [00:00<00:00, 15563.28item/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
Initializing pipeline...

Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]
Loading checkpoint shards:  25%|██▌       | 1/4 [00:40<02:02, 40.74s/it]
Loading checkpoint shards:  50%|█████     | 2/4 [01:21<01:21, 40.99s/it]
Loading checkpoint shards:  75%|███████▌  | 3/4 [01:59<00:39, 39.41s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [02:06<00:00, 26.64s/it]
Loading checkpoint shards: 100%|██████████| 4/4 [02:06<00:00, 31.62s/it]
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.
Running pipeline...
Total output tokens: 140
Avg out tokens per prompt: 70.0
model_output/meta-llama/Meta-LLaMA-3-8B-Instruct/toy/few-shot_output.pkl
model_output/meta-llama/Meta-LLaMA-3-8B-Instruct/toy/few-shot_output_METADATA.json
